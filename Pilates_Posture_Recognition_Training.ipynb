{\n "cells": [\n  {\n   "cell_type": "markdown",\n   "metadata": {},\n   "source": [\n    "# ðŸ§˜ Pilates Posture Recognition - Training Notebook\n",\n    "\n",\n    "### What This Notebook Does:\n",\n    "1. **Collects** training data from videos/images of Pilates poses\n",\n    "2. **Extracts** body landmarks using MediaPipe\n",\n    "3. **Calculates** joint angles from those landmarks\n",\n    "4. **Trains** a machine learning model to recognize postures\n",\n    "5. **Exports** the model for your Android app\n",\n    "\n",\n    "### No ML Experience Needed!\n",\n    "Just run each cell in order. ðŸ˜Š"\n   ]\n  },\n  {\n   "cell_type": "code",\n   "execution_count": null,\n   "metadata": {},\n   "outputs": [],\n   "source": [\n    "!pip install mediapipe opencv-python tensorflow scikit-learn matplotlib numpy pandas -q\n",\n    "print(\"âœ… All libraries installed successfully!\")"\n   ]\n  },\n  {\n   "cell_type": "code",\n   "execution_count": null,\n   "metadata": {},\n   "outputs": [],\n   "source": [\n    "import cv2\n",\n    "import mediapipe as mp\n",\n    "import numpy as np\n",\n    "import pandas as pd\n",\n    "import matplotlib.pyplot as plt\n",\n    "import os\n",\n    "import tensorflow as tf\n",\n    "from sklearn.model_selection import train_test_split\n",\n    "from sklearn.ensemble import RandomForestClassifier\n",\n    "from sklearn.metrics import accuracy_score, classification_report\n",\n    "import pickle\n",\n    "\n",\n    "print(\"âœ… Libraries imported successfully!\")\n",\n    "print(f\"TensorFlow version: {tf.__version__}\")\n",\n    "print(f\"MediaPipe version: {mp.__version__}\")"\n   ]\n  },\n  {\n   "cell_type": "code",\n   "execution_count": null,\n   "metadata": {},\n   "outputs": [],\n   "source": [\n    "mp_pose = mp.solutions.pose\n",\n    "mp_drawing = mp.solutions.drawing_utils\n",\n    "\n",\n    "pose = mp_pose.Pose(\n",\n    "    min_detection_confidence=0.5,\n",\n    "    min_tracking_confidence=0.5\n",\n    ")\n",\n    "\n",\n    "print(\"âœ… MediaPipe Pose initialized!\")"\n   ]\n  },\n  {\n   "cell_type": "code",\n   "execution_count": null,\n   "metadata": {},\n   "outputs": [],\n   "source": [\n    "def calculate_angle(point_a, point_b, point_c):\n",\n    "    a = np.array(point_a)\n",\n    "    b = np.array(point_b)\n",\n    "    c = np.array(point_c)\n",\n    "    \n",\n    "    ba = a - b\n",\n    "    bc = c - b\n",\n    "    \n",\n    "    cosine_angle = np.dot(ba, bc) / (np.linalg.norm(ba) * np.linalg.norm(bc))\n",\n    "    cosine_angle = np.clip(cosine_angle, -1.0, 1.0)\n",\n    "    \n",\n    "    angle = np.arccos(cosine_angle)\n",\n    "    angle_degrees = np.degrees(angle)\n",\n    "    \n",\n    "    return angle_degrees\n",\n    "\n",\n    "test_angle = calculate_angle([0, 0], [1, 0], [1, 1])\n",\n    "print(f\"âœ… Angle calculation works! Test: {test_angle:.1f}Â°\")"\n   ]\n  },\n  {\n   "cell_type": "code",\n   "execution_count": null,\n   "metadata": {},\n   "outputs": [],\n   "source": [\n    "def extract_pose_features(landmarks):\n",\n    "    try:\n",\n    "        ls = [landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].x, landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].y]\n",\n    "        le = [landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].x, landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].y]\n",\n    "        lw = [landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].x, landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].y]\n",\n    "        lh = [landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].x, landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].y]\n",\n    "        lk = [landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value].x, landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value].y]\n",\n    "        la = [landmarks[mp_pose.PoseLandmark.LEFT_ANKLE.value].x, landmarks[mp_pose.PoseLandmark.LEFT_ANKLE.value].y]\n",\n    "        rs = [landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].x, landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].y]\n",\n    "        re = [landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value].x, landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value].y]\n",\n    "        rw = [landmarks[mp_pose.PoseLandmark.RIGHT_WRIST.value].x, landmarks[mp_pose.PoseLandmark.RIGHT_WRIST.value].y]\n",\n    "        rh = [landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].x, landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].y]\n",\n    "        rk = [landmarks[mp_pose.PoseLandmark.RIGHT_KNEE.value].x, landmarks[mp_pose.PoseLandmark.RIGHT_KNEE.value].y]\n",\n    "        ra = [landmarks[mp_pose.PoseLandmark.RIGHT_ANKLE.value].x, landmarks[mp_pose.PoseLandmark.RIGHT_ANKLE.value].y]\n",\n    "        angles = [calculate_angle(ls, le, lw), calculate_angle(rs, re, rw), calculate_angle(le, ls, lh), calculate_angle(re, rs, rh), calculate_angle(ls, lh, lk), calculate_angle(rs, rh, rk), calculate_angle(lh, lk, la), calculate_angle(rh, rk, ra), calculate_angle(lh, ls, rs), calculate_angle(rh, rs, ls)]\n",\n    "        return angles\n",\n    "    except Exception as e:\n",\n    "        return [0] * 10\n",\n    "\n",\n    "print(\"âœ… Feature extraction function created!\")"\n   ]\n  },\n  {\n   "cell_type": "code",\n   "execution_count": null,\n   "metadata": {},\n   "outputs": [],\n   "source": [\n    "DATASET_PATH = '/content/pilates_dataset'\n",\n    "print(f\"Dataset path: {DATASET_PATH}\")"\n   ]\n  },\n  {\n   "cell_type": "code",\n   "execution_count": null,\n   "metadata": {},\n   "outputs": [],\n   "source": [\n    "def process_dataset(path):\n",\n    "    X, y = [], []\n",\n    "    for pose_name in os.listdir(path):\n",\n    "        pose_path = os.path.join(path, pose_name)\n",\n    "        if os.path.isdir(pose_path):\n",\n    "            for file in os.listdir(pose_path):\n",\n    "                if file.endswith(('.jpg', '.png', '.jpeg')):\n",\n    "                    img = cv2.imread(os.path.join(pose_path, file))\n",\n    "                    if img is not None:\n",\n    "                        rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",\n    "                        result = pose.process(rgb)\n",\n    "                        if result.pose_landmarks:\n",\n    "                            X.append(extract_pose_features(result.pose_landmarks.landmark))\n",\n    "                            y.append(pose_name)\n",\n    "    return np.array(X), np.array(y)\n",\n    "\n",\n    "X, y = process_dataset(DATASET_PATH)\n",\n    "print(f'Collected {len(X)} samples')"\n   ]\n  },\n  {\n   "cell_type": "code",\n   "execution_count": null,\n   "metadata": {},\n   "outputs": [],\n   "source": [\n    "from sklearn.preprocessing import LabelEncoder\n",\n    "le = LabelEncoder()\n",\n    "y_encoded = le.fit_transform(y)\n",\n    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)"\n   ]\n  },\n  {\n   "cell_type": "code",\n   "execution_count": null,\n   "metadata": {},\n   "outputs": [],\n   "source": [\n    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",\n    "model.fit(X_train, y_train)\n",\n    "print(f'Training accuracy: {model.score(X_train, y_train):.2%}')\n",\n    "print(f'Testing accuracy: {model.score(X_test, y_test):.2%}')"\n   ]\n  },\n  {\n   "cell_type": "code",\n   "execution_count": null,\n   "metadata": {},\n   "outputs": [],\n   "source": [\n    "nn_model = tf.keras.Sequential([tf.keras.layers.Dense(64, activation='relu', input_shape=(10,)), tf.keras.layers.Dropout(0.3), tf.keras.layers.Dense(32, activation='relu'), tf.keras.layers.Dense(len(le.classes_), activation='softmax')])\n",\n    "nn_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",\n    "nn_model.fit(X_train, y_train, epochs=50, validation_split=0.2, verbose=1)"\n   ]\n  },\n  {\n   "cell_type": "code",\n   "execution_count": null,\n   "metadata": {},\n   "outputs": [],\n   "source": [\n    "converter = tf.lite.TFLiteConverter.from_keras_model(nn_model)\n",\n    "tflite_model = converter.convert()\n",\n    "with open('pilates_model.tflite', 'wb') as f:\n",\n    "    f.write(tflite_model)\n",\n    "print('âœ… Model saved')"\n   ]\n  },\n  {\n   "cell_type": "code",\n   "execution_count": null,\n   "metadata": {},\n   "outputs": [],\n   "source": [\n    "with open('labels.txt', 'w') as f:\n",\n    "    for label in le.classes_:\n",\n    "        f.write(label + '\n')\n",\n    "print('âœ… Labels saved')"\n   ]\n  },\n  {\n   "cell_type": "code",\n   "execution_count": null,\n   "metadata": {},\n   "outputs": [],\n   "source": [\n    "from google.colab import files\n",\n    "files.download('pilates_model.tflite')\n",\n    "files.download('labels.txt')\n",\n    "print('âœ… Files downloaded!')"\n   ]\n  }\n ],\n "metadata": {\n  "kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"},\n  "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.8.10"}\n },\n "nbformat": 4,\n "nbformat_minor": 4\n}