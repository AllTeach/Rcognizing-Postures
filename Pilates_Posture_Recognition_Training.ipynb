{\n  "cells": [\n    {\n      "cell_type": "markdown",\n      "metadata": {},\n      "source": [\n        "# ðŸ§˜ Pilates Posture Recognition Training\n",\n        "\n",\n        "This Jupyter notebook is designed for beginners in machine learning. It guides you through the process of recognizing Pilates postures using computer vision and machine learning techniques."\n      ]\n    },\n    {\n      "cell_type": "code",\n      "execution_count": null,\n      "metadata": {},\n      "outputs": [],\n      "source": [\n        "# Step 1: Install necessary libraries\n",\n        "!pip install mediapipe opencv-python tensorflow scikit-learn pandas"\n      ]\n    },\n    {\n      "cell_type": "markdown",\n      "metadata": {},\n      "source": [\n        "## Step 2: Import Libraries\n",\n        "\n",\n        "In this section, we will import the necessary libraries for our project."\n      ]\n    },\n    {\n      "cell_type": "code",\n      "execution_count": null,\n      "metadata": {},\n      "outputs": [],\n      "source": [\n        "import cv2\n",\n        "import mediapipe as mp\n",\n        "import numpy as np\n",\n        "import tensorflow as tf\n",\n        "from sklearn.ensemble import RandomForestClassifier\n",\n        "from sklearn.model_selection import train_test_split\n",\n        "import os\n",\n        "import glob"\n      ]\n    },\n    {\n      "cell_type": "markdown",\n      "metadata": {},\n      "source": [\n        "## Step 3: Initialize MediaPipe Pose\n",\n        "\n",\n        "We will now initialize the MediaPipe Pose solution that will help us to detect key points on the human body."\n      ]\n    },\n    {\n      "cell_type": "code",\n      "execution_count": null,\n      "metadata": {},\n      "outputs": [],\n      "source": [\n        "mp_pose = mp.solutions.pose\n",\n        "pose = mp_pose.Pose(static_image_mode=True, min_detection_confidence=0.5)"\n      ]\n    },\n    {\n      "cell_type": "markdown",\n      "metadata": {},\n      "source": [\n        "## Step 4: Angle Calculation Functions\n",\n        "\n",\n        "We will define functions to calculate angles between joints. This is crucial for posture analysis."\n      ]\n    },\n    {\n      "cell_type": "code",\n      "execution_count": null,\n      "metadata": {},\n      "outputs": [],\n      "source": [\n        "def calculate_angle(a, b, c):\n",\n        "    \"\"\"Calculate angle between three points\"\"\"\n",\n        "    a = np.array(a)\n",\n        "    b = np.array(b)\n",\n        "    c = np.array(c)\n",\n        "    \n",\n        "    radians = np.arctan2(c[1] - b[1], c[0] - b[0]) - np.arctan2(a[1] - b[1], a[0] - b[0])\n",\n        "    angle = np.abs(radians * 180.0 / np.pi)\n",\n        "    \n",\n        "    if angle > 180.0:\n",\n        "        angle = 360 - angle\n",\n        "    \n",\n        "    return angle"\n      ]\n    },\n    {\n      "cell_type": "markdown",\n      "metadata": {},\n      "source": [\n        "## Step 5: Extract Pose Features\n",\n        "\n",\n        "In this section, we will extract features from pose landmarks. We will focus on 10 key joint angles."\n      ]\n    },\n    {\n      "cell_type": "code",\n      "execution_count": null,\n      "metadata": {},\n      "outputs": [],\n      "source": [\n        "def extract_pose_features(landmarks):\n",\n        "    \"\"\"Extract 10 key angles from pose landmarks\"\"\"\n",\n        "    angles = []\n",\n        "    \n",\n        "    # Left elbow\n",\n        "    angles.append(calculate_angle(\n",\n        "        [landmarks[11].x, landmarks[11].y],\n",\n        "        [landmarks[13].x, landmarks[13].y],\n",\n        "        [landmarks[15].x, landmarks[15].y]\n",\n        "    ))\n",\n        "    \n",\n        "    # Right elbow\n",\n        "    angles.append(calculate_angle(\n",\n        "        [landmarks[12].x, landmarks[12].y],\n",\n        "        [landmarks[14].x, landmarks[14].y],\n",\n        "        [landmarks[16].x, landmarks[16].y]\n",\n        "    ))\n",\n        "    \n",\n        "    # Left shoulder\n",\n        "    angles.append(calculate_angle(\n",\n        "        [landmarks[13].x, landmarks[13].y],\n",\n        "        [landmarks[11].x, landmarks[11].y],\n",\n        "        [landmarks[23].x, landmarks[23].y]\n",\n        "    ))\n",\n        "    \n",\n        "    # Right shoulder\n",\n        "    angles.append(calculate_angle(\n",\n        "        [landmarks[14].x, landmarks[14].y],\n",\n        "        [landmarks[12].x, landmarks[12].y],\n",\n        "        [landmarks[24].x, landmarks[24].y]\n",\n        "    ))\n",\n        "    \n",\n        "    # Left hip\n",\n        "    angles.append(calculate_angle(\n",\n        "        [landmarks[11].x, landmarks[11].y],\n",\n        "        [landmarks[23].x, landmarks[23].y],\n",\n        "        [landmarks[25].x, landmarks[25].y]\n",\n        "    ))\n",\n        "    \n",\n        "    # Right hip\n",\n        "    angles.append(calculate_angle(\n",\n        "        [landmarks[12].x, landmarks[12].y],\n",\n        "        [landmarks[24].x, landmarks[24].y],\n",\n        "        [landmarks[26].x, landmarks[26].y]\n",\n        "    ))\n",\n        "    \n",\n        "    # Left knee\n",\n        "    angles.append(calculate_angle(\n",\n        "        [landmarks[23].x, landmarks[23].y],\n",\n        "        [landmarks[25].x, landmarks[25].y],\n",\n        "        [landmarks[27].x, landmarks[27].y]\n",\n        "    ))\n",\n        "    \n",\n        "    # Right knee\n",\n        "    angles.append(calculate_angle(\n",\n        "        [landmarks[24].x, landmarks[24].y],\n",\n        "        [landmarks[26].x, landmarks[26].y],\n",\n        "        [landmarks[28].x, landmarks[28].y]\n",\n        "    ))\n",\n        "    \n",\n        "    # Left torso\n",\n        "    angles.append(calculate_angle(\n",\n        "        [landmarks[23].x, landmarks[23].y],\n",\n        "        [landmarks[11].x, landmarks[11].y],\n",\n        "        [landmarks[12].x, landmarks[12].y]\n",\n        "    ))\n",\n        "    \n",\n        "    # Right torso\n",\n        "    angles.append(calculate_angle(\n",\n        "        [landmarks[24].x, landmarks[24].y],\n",\n        "        [landmarks[12].x, landmarks[12].y],\n",\n        "        [landmarks[11].x, landmarks[11].y]\n",\n        "    ))\n",\n        "    \n",\n        "    return angles"\n      ]\n    },\n    {\n      "cell_type": "markdown",\n      "metadata": {},\n      "source": [\n        "## Step 6: Set Path to Your Dataset\n",\n        "\n",\n        "Update this path to point to your pilates_dataset folder."\n      ]\n    },\n    {\n      "cell_type": "code",\n      "execution_count": null,\n      "metadata": {},\n      "outputs": [],\n      "source": [\n        "# Update this path to your dataset location\n",\n        "DATASET_PATH = 'pilates_dataset'  # or '/content/drive/MyDrive/pilates_dataset' for Google Drive"\n      ]\n    },\n    {\n      "cell_type": "markdown",\n      "metadata": {},\n      "source": [\n        "## Step 7: Process All Images/Videos\n",\n        "\n",\n        "This section will process all images and videos from the pilates_dataset folder structure."\n      ]\n    },\n    {\n      "cell_type": "code",\n      "execution_count": null,\n      "metadata": {},\n      "outputs": [],\n      "source": [\n        "def process_dataset(dataset_path):\n",\n        "    X = []\n",\n        "    y = []\n",\n        "    \n",\n        "    pose_folders = [f for f in os.listdir(dataset_path) if os.path.isdir(os.path.join(dataset_path, f))]\n",\n        "    \n",\n        "    for pose_name in pose_folders:\n",\n        "        pose_dir = os.path.join(dataset_path, pose_name)\n",\n        "        print(f'Processing {pose_name}...')\n",\n        "        \n",\n        "        # Process images\n",\n        "        image_files = glob.glob(os.path.join(pose_dir, '*.jpg')) + \\n",\n        "                      glob.glob(os.path.join(pose_dir, '*.png')) + \\n",\n        "                      glob.glob(os.path.join(pose_dir, '*.jpeg'))\n",\n        "        \n",\n        "        for image_path in image_files:\n",\n        "            image = cv2.imread(image_path)\n",\n        "            image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",\n        "            results = pose.process(image_rgb)\n",\n        "            \n",\n        "            if results.pose_landmarks:\n",\n        "                features = extract_pose_features(results.pose_landmarks.landmark)\n",\n        "                X.append(features)\n",\n        "                y.append(pose_name)\n",\n        "        \n",\n        "        print(f'  Processed {len(image_files)} images for {pose_name}')\n",\n        "    \n",\n        "    return np.array(X), np.array(y)\n",\n        "\n",\n        "# Process the dataset\n",\n        "X, y = process_dataset(DATASET_PATH)\n",\n        "print(f'\\nTotal samples collected: {len(X)}')\n",\n        "print(f'Number of classes: {len(np.unique(y))}')\n",\n        "print(f'Classes: {np.unique(y)}')"\n      ]\n    },\n    {\n      "cell_type": "markdown",\n      "metadata": {},\n      "source": [\n        "## Step 8: Prepare Data for Training\n",\n        "\n",\n        "We will split the data into training and testing sets."\n      ]\n    },\n    {\n      "cell_type": "code",\n      "execution_count": null,\n      "metadata": {},\n      "outputs": [],\n      "source": [\n        "from sklearn.preprocessing import LabelEncoder\n",\n        "\n",\n        "# Encode labels\n",\n        "label_encoder = LabelEncoder()\n",\n        "y_encoded = label_encoder.fit_transform(y)\n",\n        "\n",\n        "# Split data\n",\n        "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",\n        "\n",\n        "print(f'Training samples: {len(X_train)}')\n",\n        "print(f'Testing samples: {len(X_test)}')"\n      ]\n    },\n    {\n      "cell_type": "markdown",\n      "metadata": {},\n      "source": [\n        "## Step 9: Train Random Forest Model\n",\n        "\n",\n        "In this section, we'll train a Random Forest model."\n      ]\n    },\n    {\n      "cell_type": "code",\n      "execution_count": null,\n      "metadata": {},\n      "outputs": [],\n      "source": [\n        "# Train Random Forest\n",\n        "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",\n        "rf_model.fit(X_train, y_train)\n",\n        "\n",\n        "# Evaluate\n",\n        "train_accuracy = rf_model.score(X_train, y_train)\n",\n        "test_accuracy = rf_model.score(X_test, y_test)\n",\n        "\n",\n        "print(f'Training Accuracy: {train_accuracy * 100:.2f}%')\n",\n        "print(f'Testing Accuracy: {test_accuracy * 100:.2f}%')\n",\n        "\n",\n        "# Feature importance\n",\n        "feature_names = ['Left Elbow', 'Right Elbow', 'Left Shoulder', 'Right Shoulder',\n",\n        "                 'Left Hip', 'Right Hip', 'Left Knee', 'Right Knee', \n",\n        "                 'Left Torso', 'Right Torso']\n",\n        "\n",\n        "importances = rf_model.feature_importances_\n",\n        "print('\\nMost Important Angles for Classification:')\n",\n        "for i, (name, importance) in enumerate(sorted(zip(feature_names, importances), key=lambda x: x[1], reverse=True)):\n",\n        "    print(f'{i+1}. {name}: {importance:.3f}')"\n      ]\n    },\n    {\n      "cell_type": "markdown",\n      "metadata": {},\n      "source": [\n        "## Step 10 (Optional): Train Neural Network\n",\n        "\n",\n        "We'll also demonstrate how to train a simple neural network using TensorFlow."\n      ]\n    },\n    {\n      "cell_type": "code",\n      "execution_count": null,\n      "metadata": {},\n      "outputs": [],\n      "source": [\n        "# Build neural network\n",\n        "model = tf.keras.models.Sequential([\n",\n        "    tf.keras.layers.Dense(128, activation='relu', input_shape=(10,)),\n",\n        "    tf.keras.layers.Dropout(0.3),\n",\n        "    tf.keras.layers.Dense(64, activation='relu'),\n",\n        "    tf.keras.layers.Dropout(0.3),\n",\n        "    tf.keras.layers.Dense(len(label_encoder.classes_), activation='softmax')\n",\n        "])\n",\n        "\n",\n        "model.compile(optimizer='adam', \n",\n        "              loss='sparse_categorical_crossentropy', \n",\n        "              metrics=['accuracy'])\n",\n        "\n",\n        "# Train\n",\n        "history = model.fit(X_train, y_train, \n",\n        "                    epochs=50, \n",\n        "                    validation_data=(X_test, y_test),\n",\n        "                    verbose=1)\n",\n        "\n",\n        "# Evaluate\n",\n        "test_loss, test_acc = model.evaluate(X_test, y_test)\n",\n        "print(f'\\nNeural Network Test Accuracy: {test_acc * 100:.2f}%')"\n      ]\n    },\n    {\n      "cell_type": "markdown",\n      "metadata": {},\n      "source": [\n        "## Step 11: Convert to Android Format (TFLite)\n",\n        "\n",\n        "Let's convert our trained model to TFLite format for mobile deployment."\n      ]\n    },\n    {\n      "cell_type": "code",\n      "execution_count": null,\n      "metadata": {},\n      "outputs": [],\n      "source": [\n        "# Convert to TFLite\n",\n        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",\n        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",\n        "tflite_model = converter.convert()\n",\n        "\n",\n        "# Save the model\n",\n        "with open('pilates_model.tflite', 'wb') as f:\n",\n        "    f.write(tflite_model)\n",\n        "\n",\n        "print('Model converted to TFLite format!')\n",\n        "print(f'Model size: {len(tflite_model) / 1024:.2f} KB')"\n      ]\n    },\n    {\n      "cell_type": "markdown",\n      "metadata": {},\n      "source": [\n        "## Step 12: Save Pose Labels\n",\n        "\n",\n        "We will save the labels to a txt file for our model."\n      ]\n    },\n    {\n      "cell_type": "code",\n      "execution_count": null,\n      "metadata": {},\n      "outputs": [],\n      "source": [\n        "# Save labels\n",\n        "with open('labels.txt', 'w') as file:\n",\n        "    for label in label_encoder.classes_:\n",\n        "        file.write(f'{label}\n')\n",\n        "\n",\n        "print('Labels saved to labels.txt')\n",\n        "print('\\nLabel mapping:')\n",\n        "for i, label in enumerate(label_encoder.classes_):\n",\n        "    print(f'{i}: {label}')"\n      ]\n    },\n    {\n      "cell_type": "markdown",\n      "metadata": {},\n      "source": [\n        "## Step 13: Download Your Model Files\n",\n        "\n",\n        "Finally, we'll download our trained model and labels file."\n      ]\n    },\n    {\n      "cell_type": "code",\n      "execution_count": null,\n      "metadata": {},\n      "outputs": [],\n      "source": [\n        "from google.colab import files\n",\n        "\n",\n        "# Download files\n",\n        "files.download('pilates_model.tflite')\n",\n        "files.download('labels.txt')\n",\n        "\n",\n        "print('âœ… Files downloaded! Add them to your Android project.')"\n      ]\n    }\n  ],\n  "metadata": {\n    "kernelspec": {\n      "display_name": "Python 3",\n      "language": "python",\n      "name": "python3"\n    },\n    "language_info": {\n      "codemirror_mode": {\n        "name": "ipython",\n        "version": 3\n      },\n      "file_extension": ".py",\n      "mimetype": "text/x-python",\n      "name": "python",\n      "nbconvert_exporter": "python",\n      "pygments_lexer": "ipython3",\n      "version": "3.8.10"\n    }\n  },\n  "nbformat": 4,\n  "nbformat_minor": 4\n}