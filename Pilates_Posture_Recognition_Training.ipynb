{\n "cells": [\n  {\n   "cell_type": "markdown",\n   "metadata": {},\n   "source": [\n    "# üßò Pilates Posture Recognition - Complete Training Notebook\n",\n    "\n",\n    "### What This Notebook Does:\n",\n    "1. **Collects** training data from videos/images of Pilates poses\n",\n    "2. **Extracts** body landmarks (keypoints) using MediaPipe\n",\n    "3. **Calculates** joint angles from those landmarks\n",\n    "4. **Trains** a machine learning model to recognize different Pilates postures\n",\n    "5. **Exports** the model to use in your Android app\n",\n    "\n",\n    "### No ML Experience Needed!\n",\n    "Just run each cell in order and follow the instructions. üòä"\n   ]\n  },\n  {\n   "cell_type": "markdown",\n   "metadata": {},\n   "source": [\n    "---\n",\n    "## Step 1: Install Required Libraries\n",\n    "\n",\n    "**What this does:** Installs the tools we need:\n",\n    "- `mediapipe`: Detects body poses\n",\n    "- `opencv-python`: Processes videos/images\n",\n    "- `tensorflow`: Trains our AI model\n",\n    "- `scikit-learn`: Helps with machine learning tasks"\n   ]\n  },\n  {\n   "cell_type": "code",\n   "execution_count": null,\n   "metadata": {},\n   "outputs": [],\n   "source": [\n    "# Install necessary libraries (this may take 1-2 minutes)\n",\n    "!pip install mediapipe opencv-python tensorflow scikit-learn matplotlib numpy pandas -q\n",\n    "\n",\n    "print(\"‚úÖ All libraries installed successfully!\")"\n   ]\n  },\n  {\n   "cell_type": "markdown",\n   "metadata": {},\n   "source": [\n    "---\n",\n    "## Step 2: Import Libraries\n",\n    "\n",\n    "**What this does:** Loads all the tools we just installed so we can use them."\n   ]\n  },\n  {\n   "cell_type": "code",\n   "execution_count": null,\n   "metadata": {},\n   "outputs": [],\n   "source": [\n    "import cv2\n",\n    "import mediapipe as mp\n",\n    "import numpy as np\n",\n    "import pandas as pd\n",\n    "import matplotlib.pyplot as plt\n",\n    "import os\n",\n    "import tensorflow as tf\n",\n    "from sklearn.model_selection import train_test_split\n",\n    "from sklearn.ensemble import RandomForestClassifier\n",\n    "from sklearn.metrics import accuracy_score, classification_report\n",\n    "import pickle\n",\n    "\n",\n    "print(\"‚úÖ Libraries imported successfully!\")\n",\n    "print(f\"TensorFlow version: {tf.__version__}\")\n",\n    "print(f\"MediaPipe version: {mp.__version__}\")"\n   ]\n  },\n  {\n   "cell_type": "markdown",\n   "metadata": {},\n   "source": [\n    "---\n",\n    "## Step 3: Initialize MediaPipe Pose\n",\n    "\n",\n    "**What this does:** Sets up MediaPipe to detect body poses.\n",\n    "\n",\n    "MediaPipe will find 33 keypoints on the body (shoulders, hips, knees, etc.)"\n   ]\n  },\n  {\n   "cell_type": "code",\n   "execution_count": null,\n   "metadata": {},\n   "outputs": [],\n   "source": [\n    "# Initialize MediaPipe Pose\n",\n    "mp_pose = mp.solutions.pose\n",\n    "mp_drawing = mp.solutions.drawing_utils\n",\n    "\n",\n    "# Create a Pose detector\n",\n    "pose = mp_pose.Pose(\n",\n    "    min_detection_confidence=0.5,\n",\n    "    min_tracking_confidence=0.5\n",\n    ")\n",\n    "\n",\n    "print(\"‚úÖ MediaPipe Pose initialized!\")"\n   ]\n  },\n  {\n   "cell_type": "markdown",\n   "metadata": {},\n   "source": [\n    "---\n",\n    "## Step 4: Helper Functions - Calculate Angles\n",\n    "\n",\n    "**What this does:** Creates a function to calculate the angle between three body points."\n   ]\n  },\n  {\n   "cell_type": "code",\n   "execution_count": null,\n   "metadata": {},\n   "outputs": [],\n   "source": [\n    "def calculate_angle(point_a, point_b, point_c):\n",\n    "    a = np.array(point_a)\n",\n    "    b = np.array(point_b)\n",\n    "    c = np.array(point_c)\n",\n    "    \n",\n    "    ba = a - b\n",\n    "    bc = c - b\n",\n    "    \n",\n    "    cosine_angle = np.dot(ba, bc) / (np.linalg.norm(ba) * np.linalg.norm(bc))\n",\n    "    cosine_angle = np.clip(cosine_angle, -1.0, 1.0)\n",\n    "    \n",\n    "    angle = np.arccos(cosine_angle)\n",\n    "    angle_degrees = np.degrees(angle)\n",\n    "    \n",\n    "    return angle_degrees\n",\n    "\n",\n    "test_angle = calculate_angle([0, 0], [1, 0], [1, 1])\n",\n    "print(f\"‚úÖ Angle calculation function created! Test angle: {test_angle:.1f}¬∞\")"\n   ]\n  },\n  {\n   "cell_type": "markdown",\n   "metadata": {},\n   "source": [\n    "---\n",\n    "## Step 5: Extract Features from Pose"\n   ]\n  },\n  {\n   "cell_type": "code",\n   "execution_count": null,\n   "metadata": {},\n   "outputs": [],\n   "source": [\n    "def extract_pose_features(landmarks):\n",\n    "    try:\n",\n    "        left_shoulder = [landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].x,\n",\n    "                        landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].y]\n",\n    "        left_elbow = [landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].x,\n",\n    "                     landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].y]\n",\n    "        left_wrist = [landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].x,\n",\n    "                     landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].y]\n",\n    "        left_hip = [landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].x,\n",\n    "                   landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].y]\n",\n    "        left_knee = [landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value].x,\n",\n    "                    landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value].y]\n",\n    "        left_ankle = [landmarks[mp_pose.PoseLandmark.LEFT_ANKLE.value].x,\n",\n    "                     landmarks[mp_pose.PoseLandmark.LEFT_ANKLE.value].y]\n",\n    "        \n",\n    "        right_shoulder = [landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].x,\n",\n    "                         landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].y]\n",\n    "        right_elbow = [landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value].x,\n",\n    "                      landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value].y]\n",\n    "        right_wrist = [landmarks[mp_pose.PoseLandmark.RIGHT_WRIST.value].x,\n",\n    "                      landmarks[mp_pose.PoseLandmark.RIGHT_WRIST.value].y]\n",\n    "        right_hip = [landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].x,\n",\n    "                    landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].y]\n",\n    "        right_knee = [landmarks[mp_pose.PoseLandmark.RIGHT_KNEE.value].x,\n",\n    "                     landmarks[mp_pose.PoseLandmark.RIGHT_KNEE.value].y]\n",\n    "        right_ankle = [landmarks[mp_pose.PoseLandmark.RIGHT_ANKLE.value].x,\n",\n    "                      landmarks[mp_pose.PoseLandmark.RIGHT_ANKLE.value].y]\n",\n    "        \n",\n    "        angles = [\n",\n    "            calculate_angle(left_shoulder, left_elbow, left_wrist),\n",\n    "            calculate_angle(right_shoulder, right_elbow, right_wrist),\n",\n    "            calculate_angle(left_elbow, left_shoulder, left_hip),\n",\n    "            calculate_angle(right_elbow, right_shoulder, right_hip),\n",\n    "            calculate_angle(left_shoulder, left_hip, left_knee),\n",\n    "            calculate_angle(right_shoulder, right_hip, right_knee),\n",\n    "            calculate_angle(left_hip, left_knee, left_ankle),\n",\n    "            calculate_angle(right_hip, right_knee, right_ankle),\n",\n    "            calculate_angle(left_hip, left_shoulder, right_shoulder),\n",\n    "            calculate_angle(right_hip, right_shoulder, left_shoulder)\n",\n    "        ]\n",\n    "        \n",\n    "        return angles\n",\n    "    \n",\n    "    except Exception as e:\n",\n    "        print(f\"Error extracting features: {e}\")\n",\n    "        return [0] * 10\n",\n    "\n",\n    "print(\"‚úÖ Feature extraction function created!\")"\n   ]\n  },\n  {\n   "cell_type": "markdown",\n   "metadata": {},\n   "source": [\n    "---\n",\n    "## Step 6: Set Path to Your Dataset"\n   ]\n  },\n  {\n   "cell_type": "code",\n   "execution_count": null,\n   "metadata": {},\n   "outputs": [],\n   "source": [\n    "DATASET_PATH = '/content/pilates_dataset'\n",\n    "\n",\n    "print(f\"Dataset path set to: {DATASET_PATH}\")"\n   ]\n  },\n  {\n   "cell_type": "markdown",\n   "metadata": {},\n   "source": [\n    "---\n",\n    "## Step 7: Process All Images/Videos"\n   ]\n  },\n  {\n   "cell_type": "code",\n   "execution_count": null,\n   "metadata": {},\n   "outputs": [],\n   "source": [\n    "def process_dataset(dataset_path):\n",\n    "    features = []\n",\n    "    labels = []\n",\n    "    \n",\n    "    image_extensions = ['.jpg', '.jpeg', '.png']\n",\n    "    video_extensions = ['.mp4', '.avi', '.mov']\n",\n    "    \n",\n    "    if not os.path.exists(dataset_path):\n",\n    "        print(f\"‚ùå Error: Dataset path not found!\")\n",\n    "        return [], []\n",\n    "    \n",\n    "    pose_folders = [f for f in os.listdir(dataset_path) if os.path.isdir(os.path.join(dataset_path, f))]\n",\n    "    \n",\n    "    print(f\"Found {len(pose_folders)} pose types\\n\")\n",\n    "    \n",\n    "    for pose_name in pose_folders:\n",\n    "        pose_folder_path = os.path.join(dataset_path, pose_name)\n",\n    "        files = os.listdir(pose_folder_path)\n",\n    "        \n",\n    "        print(f\"Processing '{pose_name}'...\")\n",\n    "        samples_collected = 0\n",\n    "        \n",\n    "        for filename in files:\n",\n    "            file_path = os.path.join(pose_folder_path, filename)\n",\n    "            file_ext = os.path.splitext(filename)[1].lower()\n",\n    "            \n",\n    "            if file_ext in image_extensions:\n",\n    "                image = cv2.imread(file_path)\n",\n    "                if image is None:\n",\n    "                    continue\n",\n    "                \n",\n    "                image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",\n    "                results = pose.process(image_rgb)\n",\n    "                \n",\n    "                if results.pose_landmarks:\n",\n    "                    angles = extract_pose_features(results.pose_landmarks.landmark)\n",\n    "                    features.append(angles)\n",\n    "                    labels.append(pose_name)\n",\n    "                    samples_collected += 1\n",\n    "        \n",\n    "        print(f\"  ‚úÖ Collected {samples_collected} samples\\n\")\n",\n    "    \n",\n    "    print(f\"Total samples: {len(features)}\")\n",\n    "    return features, labels\n",\n    "\n",\n    "X, y = process_dataset(DATASET_PATH)\n",\n    "\n",\n    "if len(X) > 0:\n",\n    "    print(\"‚úÖ Dataset processed successfully!\")\n",\n    "else:\n",\n    "    print(\"‚ùå No data collected\")"\n   ]\n  },\n  {\n   "cell_type": "markdown",\n   "metadata": {},\n   "source": [\n    "---\n",\n    "## Step 8: Prepare Data for Training"\n   ]\n  },\n  {\n   "cell_type": "code",\n   "execution_count": null,\n   "metadata": {},\n   "outputs": [],\n   "source": [\n    "X = np.array(X)\n",\n    "y = np.array(y)\n",\n    "\n",\n    "pose_classes = sorted(list(set(y)))\n",\n    "pose_to_number = {pose: idx for idx, pose in enumerate(pose_classes)}\n",\n    "number_to_pose = {idx: pose for pose, idx in pose_to_number.items()}\n",\n    "\n",\n    "y_numeric = np.array([pose_to_number[pose] for pose in y])\n",\n    "\n",\n    "X_train, X_test, y_train, y_test = train_test_split(X, y_numeric, test_size=0.2, random_state=42, stratify=y_numeric)\n",\n    "\n",\n    "print(f\"Training samples: {len(X_train)}\")\n",\n    "print(f\"Testing samples: {len(X_test)}\")"\n   ]\n  },\n  {\n   "cell_type": "markdown",\n   "metadata": {},\n   "source": [\n    "---\n",\n    "## Step 9: Train Random Forest Model"\n   ]\n  },\n  {\n   "cell_type": "code",\n   "execution_count": null,\n   "metadata": {},\n   "outputs": [],\n   "source": [\n    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42, max_depth=10, n_jobs=-1)\n",\n    "\n",\n    "print(\"Training Random Forest model...\\n\")\n",\n    "rf_model.fit(X_train, y_train)\n",\n    "\n",\n    "train_predictions = rf_model.predict(X_train)\n",\n    "test_predictions = rf_model.predict(X_test)\n",\n    "\n",\n    "train_accuracy = accuracy_score(y_train, train_predictions)\n",\n    "test_accuracy = accuracy_score(y_test, test_predictions)\n",\n    "\n",\n    "print(f\"Training Accuracy: {train_accuracy * 100:.2f}%\")\n",\n    "print(f\"Testing Accuracy: {test_accuracy * 100:.2f}%\")"\n   ]\n  },\n  {\n   "cell_type": "markdown",\n   "metadata": {},\n   "source": [\n    "---\n",\n    "## Step 10: Train Neural Network (Optional)"\n   ]\n  },\n  {\n   "cell_type": "code",\n   "execution_count": null,\n   "metadata": {},\n   "outputs": [],\n   "source": [\n    "y_train_onehot = tf.keras.utils.to_categorical(y_train, num_classes=len(pose_classes))\n",\n    "y_test_onehot = tf.keras.utils.to_categorical(y_test, num_classes=len(pose_classes))\n",\n    "\n",\n    "nn_model = tf.keras.Sequential([\n",\n    "    tf.keras.layers.Input(shape=(10,)),\n",\n    "    tf.keras.layers.Dense(64, activation='relu'),\n",\n    "    tf.keras.layers.Dropout(0.3),\n",\n    "    tf.keras.layers.Dense(32, activation='relu'),\n",\n    "    tf.keras.layers.Dropout(0.3),\n",\n    "    tf.keras.layers.Dense(len(pose_classes), activation='softmax')\n",\n    "])\n",\n    "\n",\n    "nn_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",\n    "\n",\n    "history = nn_model.fit(X_train, y_train_onehot, epochs=50, batch_size=32, validation_split=0.2, verbose=1)\n",\n    "\n",\n    "test_loss, test_accuracy = nn_model.evaluate(X_test, y_test_onehot, verbose=0)\n",\n    "print(f\"Neural Network Test Accuracy: {test_accuracy * 100:.2f}%\")"\n   ]\n  },\n  {\n   "cell_type": "markdown",\n   "metadata": {},\n   "source": [\n    "---\n",\n    "## Step 11: Convert to TFLite"\n   ]\n  },\n  {\n   "cell_type": "code",\n   "execution_count": null,\n   "metadata": {},\n   "outputs": [],\n   "source": [\n    "converter = tf.lite.TFLiteConverter.from_keras_model(nn_model)\n",\n    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",\n    "tflite_model = converter.convert()\n",\n    "\n",\n    "with open('pilates_model.tflite', 'wb') as f:\n",\n    "    f.write(tflite_model)\n",\n    "\n",\n    "print(f\"Model size: {len(tflite_model) / 1024:.2f} KB\")"\n   ]\n  },\n  {\n   "cell_type": "markdown",\n   "metadata": {},\n   "source": [\n    "---\n",\n    "## Step 12: Save Labels"\n   ]\n  },\n  {\n   "cell_type": "code",\n   "execution_count": null,\n   "metadata": {},\n   "outputs": [],\n   "source": [\n    "with open('labels.txt', 'w') as file:\n",\n    "    for label in pose_classes:\n",\n    "        file.write(label + '\\n')\n",\n    "\n",\n    "print(\"‚úÖ Labels saved\")"\n   ]\n  },\n  {\n   "cell_type": "markdown",\n   "metadata": {},\n   "source": [\n    "---\n",\n    "## Step 13: Download Files"\n   ]\n  },\n  {\n   "cell_type": "code",\n   "execution_count": null,\n   "metadata": {},\n   "outputs": [],\n   "source": [\n    "from google.colab import files\n",\n    "\n",\n    "files.download('pilates_model.tflite')\n",\n    "files.download('labels.txt')\n",\n    "\n",\n    "print(\"‚úÖ Files downloaded!\")"\n   ]\n  }\n ],\n "metadata": {\n  "kernelspec": {\n   "display_name": "Python 3",\n   "language": "python",\n   "name": "python3"\n  },\n  "language_info": {\n   "codemirror_mode": {\n    "name": "ipython",\n    "version": 3\n   },\n   "file_extension": ".py",\n   "mimetype": "text/x-python",\n   "name": "python",\n   "nbconvert_exporter": "python",\n   "pygments_lexer": "ipython3",\n   "version": "3.8.10"\n  }\n },\n "nbformat": 4,\n "nbformat_minor": 4\n}